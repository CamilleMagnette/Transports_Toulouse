# ğŸšŒ ğŸš² ğŸš— Transports_Toulouse

Il s'agit ici du rÃ©sultat du 3Ã¨me projet menÃ© pendant ma formation Ã  la Wild Code School.


## ğŸ¯ Objectif du projet :

RÃ©cupÃ©rer des donnÃ©es open data auprÃ¨s de sociÃ©tÃ©s de transports (publiques ou privÃ©es) et faire une proposition d'application utilisateurs. 


## ğŸ” Sources des donnÃ©es :  

- Parkings : [APIÂ data.toulouse-mÃ©tropole.fr](https://data.toulouse-metropole.fr/pages/accueil/)   
Fichiers csv sources parkings relais et indigo

- Stations vÃ©lÃ´Toulouse : [API transport.data.gouv.fr](https://transport.data.gouv.fr/)  
Fichier Json disponibilitÃ© en temps rÃ©el 

- Stations bus, metro, tram : [API tisseo.fr](https://api.tisseo.fr/)   
Fichier Json arrÃªts et horaires en temps rÃ©el 


## ğŸ“ MÃ©thodologie technique :

1) RÃ©cupÃ©ration et nettoyage des donnÃ©es auprÃ¨s des API ciblÃ©es

2) Consolidation et prÃ©paration des donnÃ©es pour la crÃ©ation de l'application utilisateur

3) Mise en place de l'application utilisateur avec Dash

<img src="https://github.com/CamilleMagnette/Transports_Toulouse/blob/main/images/etapes.png" width=70% height=70%>


## âœ… Etapes : 

#### Semaine 1 :  
Appropriation et premiÃ¨re exploration des donnÃ©es     
Outils principaux : Pandas, Matplotlib, jupyterLab   

[LIEN DIAGRAMME DE RETRAVAIL DES TABLES ğŸ’ª ğŸ•º](https://drive.google.com/file/d/17TfOcP2BalAt5omnFj4_L5hGJK4bfPqt/view?usp=sharing)

#### Semaines 2 et 3 : 
Jointures, filtres, nettoyage, recherche de corrÃ©lation     
Outils principaux : Pandas, Seaborn, DataPane, jupyterLab

[LIEN ANALYSE DES DONNEES SOUS DATAPANE ğŸ’¡ ğŸ“Š](https://cloud.datapane.com/reports/VkGQlN3/exploration-des-donn%C3%A9es/)



4) [Tests de machine learning](http://localhost:8891/lab/tree/Documents/FORMATION%20DATA%20ANALYST/COURS%20DATA%20ANALYST/PROJET%202/JUPITERLAB%20NOTEBOOKS/Projet%202%20-%20Machine%20learning%20TEST%20ACTEURS.ipynb) : normalisation des donnÃ©es et mise en place d'un algorithme basÃ© sur les plus proches voisins (algorithme K-nearest neighbors (kNN))
